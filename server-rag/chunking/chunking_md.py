from langchain_text_splitters import MarkdownHeaderTextSplitter
from typing import List
import os

def chunk_markdown_file(file_path: str) -> List:
    # ì£¼ì–´ì§„ ê²½ë¡œì˜ ë§ˆí¬ë‹¤ìš´ íŒŒì¼ì„ ì½ì–´ H1(#), H2(##) í—¤ë”ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• .

    filename = os.path.basename(file_path)
    print(f"\nğŸ“– ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì²˜ë¦¬: {filename}")

    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            markdown_text = f.read()
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return []

    # ë¶„í•  ê¸°ì¤€ì´ ë  í—¤ë”ë¥¼ ì •ì˜
    headers_to_split_on = [
        ("#", "Header 1"),
        ("##", "Header 2"),
    ]

    # MarkdownHeaderTextSplitter ì´ˆê¸°í™”
    markdown_splitter = MarkdownHeaderTextSplitter(
        headers_to_split_on=headers_to_split_on, 
        return_each_line=False
    )

    # í…ìŠ¤íŠ¸ ë¶„í•  ì‹¤í–‰
    print(f"\nâœ‚ï¸ ë§ˆí¬ë‹¤ìš´ í—¤ë” ê¸°ì¤€ìœ¼ë¡œ ë¶„í•  ì¤‘...")
    initial_chunks = markdown_splitter.split_text(markdown_text)
    print(f"ğŸ“Š ì´ˆê¸° ë¶„í•  ê²°ê³¼: {len(initial_chunks)}ê°œ ì²­í¬")

    # ë©”íƒ€ë°ì´í„° í›„ì²˜ë¦¬
    processed_chunks = []
    for i, chunk in enumerate(initial_chunks):
        chunk.metadata['source'] = filename
        
        # Header 2ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ feature ì¶”ê°€
        header2 = chunk.metadata.get('Header 2', '')
        if header2:
            new_page_content = f'\n---\nfeature: {header2}\n{chunk.page_content}'
        else:
            new_page_content = f'\n---\nfeature: Unknown\n{chunk.page_content}'
            
        chunk.page_content = new_page_content
        processed_chunks.append(chunk)
        
        # print(f"   ì²˜ë¦¬ëœ ì²­í¬ {i+1}: feature='{header2 if header2 else 'Unknown'}'")

    print(f"\nâœ… ì´ {len(processed_chunks)}ê°œ ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ")
    return processed_chunks