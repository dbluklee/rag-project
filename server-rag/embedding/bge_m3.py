import torch
from langchain_huggingface import HuggingFaceEmbeddings
import os

def get_bge_m3_model() -> HuggingFaceEmbeddings:
    """
    BGE-M3 ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    í™˜ê²½ë³€ìˆ˜ë‚˜ ë©”ëª¨ë¦¬ ìƒí™©ì— ë”°ë¼ CPU/GPUë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    """
    
    # í™˜ê²½ë³€ìˆ˜ë¡œ CPU ê°•ì œ ì„¤ì • í™•ì¸
    force_cpu = os.getenv('FORCE_CPU', 'false').lower() == 'true'
    cuda_visible = os.getenv('CUDA_VISIBLE_DEVICES', '')
    
    if force_cpu or cuda_visible == '':
        print("ğŸ”§ í™˜ê²½ë³€ìˆ˜ì— ì˜í•´ CPU ì‚¬ìš©ìœ¼ë¡œ ì„¤ì •ë¨")
        device = 'cpu'
    elif torch.cuda.is_available():
        # GPU ë©”ëª¨ë¦¬ í™•ì¸
        try:
            gpu_memory = torch.cuda.get_device_properties(0).total_memory
            gpu_free = torch.cuda.memory_reserved(0) - torch.cuda.memory_allocated(0)
            gpu_memory_gb = gpu_memory / (1024**3)
            gpu_free_gb = gpu_free / (1024**3)
            
            print(f"ğŸ” GPU ì „ì²´ ë©”ëª¨ë¦¬: {gpu_memory_gb:.1f}GB")
            print(f"ğŸ” GPU ì—¬ìœ  ë©”ëª¨ë¦¬: {gpu_free_gb:.1f}GB")
            
            # ì—¬ìœ  ë©”ëª¨ë¦¬ê°€ 2GB ë¯¸ë§Œì´ë©´ CPU ì‚¬ìš©
            if gpu_free_gb < 2.0:
                print("âš ï¸ GPU ë©”ëª¨ë¦¬ ë¶€ì¡± - CPU ì‚¬ìš©ìœ¼ë¡œ ì „í™˜")
                device = 'cpu'
            else:
                device = 'cuda'
        except:
            print("âš ï¸ GPU ìƒíƒœ í™•ì¸ ì‹¤íŒ¨ - CPU ì‚¬ìš©")
            device = 'cpu'
    else:
        print("âš ï¸ CUDA ì‚¬ìš© ë¶ˆê°€ - CPU ì‚¬ìš©")
        device = 'cpu'
    
    print(f"ğŸ”§ ì„ë² ë”© ëª¨ë¸ ë””ë°”ì´ìŠ¤: {device}")
    
    model_name = 'BAAI/bge-m3'
    model_kwargs = {'device': device}
    encode_kwargs = {'normalize_embeddings': True}
    
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name=model_name,
            model_kwargs=model_kwargs,
            encode_kwargs=encode_kwargs
        )
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({device})")
        return embeddings
    except Exception as e:
        if device == 'cuda':
            print(f"âŒ GPU ë¡œë”© ì‹¤íŒ¨: {e}")
            print("ğŸ”„ CPUë¡œ ì¬ì‹œë„...")
            model_kwargs = {'device': 'cpu'}
            embeddings = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs
            )
            print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ (CPU ëŒ€ì²´)")
            return embeddings
        else:
            raise e