# 모델 설정
models:
  rag_model_name: "rag-cheeseade:latest"
  llm_model_name: "gemma3:27b-it-q4_K_M"
  evaluator_model: "gemma3:27b-it-q4_K_M"  # RAGAS 평가용 모델 (내부 LLM 서버)
  # 임베딩은 RAG 서버 내부 것을 자동으로 사용 (설정 불필요)# CHEESEADE RAG 평가 설정

# 서버 정보
servers:
  rag_server_url: "http://112.148.37.41:1886"
  llm_server_url: "http://112.148.37.41:1884"
  health_check_timeout: 10

# 모델 설정
models:
  rag_model_name: "rag-cheeseade:latest"
  llm_model_name: "gemma3:27b-it-q4_K_M"
  evaluator_model: "gemma3:27b-it-q4_K_M"  # RAGAS 평가용 모델 (내부 서버 사용)
  embedding_model: "BAAI/bge-m3"  # 내부 서버 임베딩 모델

# 데이터 경로
data_paths:
  questions_file: "evaluation/data/questions.xlsx"
  ground_truth_file: "evaluation/data/ground_truth.xlsx"
  output_dir: "evaluation/results"
  logs_dir: "evaluation/logs"

# RAGAS 평가 메트릭
ragas_metrics:
  - "faithfulness"          # 답변이 context에 근거하는지
  - "answer_relevancy"      # 답변이 질문과 관련있는지  
  - "context_precision"     # 검색된 context가 정확한지
  - "context_recall"        # 필요한 context를 모두 검색했는지
  - "context_relevancy"     # 검색된 context가 관련있는지
  - "answer_similarity"     # 정답과의 유사도
  - "answer_correctness"    # 답변의 정확성

# 평가 설정
evaluation:
  batch_size: 10            # 배치 크기
  max_workers: 4            # 병렬 처리 워커 수
  timeout_per_question: 30  # 질문당 타임아웃 (초)
  retry_count: 3            # 실패시 재시도 횟수
  sample_size: null         # null이면 전체, 숫자면 샘플링
  
# 출력 설정
output:
  save_individual_results: true     # 개별 결과 저장
  save_aggregated_results: true     # 집계 결과 저장
  generate_charts: true             # 차트 생성
  generate_html_report: true        # HTML 보고서 생성
  export_to_excel: true            # Excel 내보내기

# 로깅 설정
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file_handler: true
  console_handler: true

# 시각화 설정
visualization:
  figure_size: [12, 8]
  dpi: 300
  style: "seaborn-v0_8"
  color_palette: "Set2"
  
# 통계 설정
statistics:
  confidence_interval: 0.95
  significance_level: 0.05
  
# 성능 임계값 (경고용)
thresholds:
  faithfulness: 0.8
  answer_relevancy: 0.75
  context_precision: 0.7
  context_recall: 0.7
  overall_score: 0.75