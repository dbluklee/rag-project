def get_retrieved_contexts(self, question: str) -> List[str]:
        """ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ë””ë²„ê·¸ API ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            debug_payload = {"question": question}
            
            response = requests.post(
                f"{self.rag_server_url}/debug/test-retrieval",
                json=debug_payload,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                contexts = []
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                retrieved_docs = result.get('retrieved_docs', [])
                for doc in retrieved_docs:
                    if isinstance(doc, dict):
                        content = doc.get('page_content', '')
                        if content:
                            contexts.append(content)
                    elif isinstance(doc, str):
                        contexts.append(doc)
                
                return contexts[:4]  # ìƒìœ„ 4ê°œë§Œ
            else:
                self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def get_rag_embeddings_for_ragas(self):
        """RAGAS í‰ê°€ìš© ì„ë² ë”© ë˜í¼ ìƒì„±"""
        return RAGServerEmbeddingsWrapper(
            rag_server_url=self.rag_server_url,
            logger=self.logger
        )


class RAGServerEmbeddingsWrapper:
    """RAG ì„œë²„ì˜ ì„ë² ë”©ì„ RAGASì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë˜í¼"""
    
    def __init__(self, rag_server_url: str, logger):
        self.rag_server_url = rag_server_url
        self.logger = logger
        
        # ì‹¤ì œ RAG ì„œë²„ ì„ë² ë”© ëª¨ë¸ê³¼ ë™ì¼í•œ ëª¨ë¸ ë¡œë“œ
        # ì´ë ‡ê²Œ í•˜ë©´ RAG ì„œë²„ì˜ ì²­í‚¹/ì„ë² ë”©/ë¦¬íŠ¸ë¦¬ë²„ ë³€ê²½ì´ ìë™ìœ¼ë¡œ ë°˜ì˜ë¨
        try:
            from embedding.bge_m3 import get_bge_m3_model
            self.embedding_model = get_bge_m3_model()
            self.logger.info("âœ… RAG ì„œë²„ì™€ ë™ì¼í•œ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            self.logger.error(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def embed_documents(self, texts):
        """ë¬¸ì„œ ì„ë² ë”© (RAG ì„œë²„ì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            return self.embedding_model.embed_documents(texts)
        except Exception as e:
            self.logger.error(f"âŒ ë¬¸ì„œ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            raise
    
    def embed_query(self, text):
        """ì¿¼ë¦¬ ì„ë² ë”© (RAG ì„œë²„ì™€ ë™ì¼í•œ ëª¨ë¸ ì‚¬ìš©)"""
        try:
            return self.embedding_model.embed_query(text)
        except Exception as e:
            self.logger.error(f"âŒ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")
            raise"""
CHEESEADE RAG ì‹œìŠ¤í…œ í‰ê°€ê¸°
RAGASë¥¼ ì‚¬ìš©í•œ ì¢…í•©ì ì¸ ì„±ëŠ¥ í‰ê°€
"""

import os
import yaml
import asyncio
import logging
import pandas as pd
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
import requests
from tqdm import tqdm
import json

# RAGAS ê´€ë ¨
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy, 
    context_precision,
    context_recall,
    context_relevancy,
    answer_similarity,
    answer_correctness
)
from datasets import Dataset

class CheeseadeRAGEvaluator:
    """CHEESEADE RAG ì‹œìŠ¤í…œ í‰ê°€ í´ë˜ìŠ¤"""
    
    def __init__(self, config_path: str = "evaluation/config.yaml"):
        """í‰ê°€ê¸° ì´ˆê¸°í™”"""
        self.config = self._load_config(config_path)
        self.setup_logging()
        self.setup_directories()
        
        # ì„œë²„ ì—°ê²° ì •ë³´
        self.rag_server_url = self.config['servers']['rag_server_url']
        self.llm_server_url = self.config['servers']['llm_server_url']
        
        # ëª¨ë¸ ì •ë³´
        self.rag_model_name = self.config['models']['rag_model_name']
        self.llm_model_name = self.config['models']['llm_model_name']
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥ìš©
        self.evaluation_results = {}
        self.individual_results = []
        
        self.logger.info("ğŸš€ CHEESEADE RAG í‰ê°€ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"âœ… ì„¤ì • íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {config_path}")
            return config
        except Exception as e:
            print(f"âŒ ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        log_config = self.config['logging']
        
        # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
        log_dir = Path(self.config['data_paths']['logs_dir'])
        log_dir.mkdir(parents=True, exist_ok=True)
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger('CheeseadeRAGEvaluator')
        self.logger.setLevel(getattr(logging, log_config['level']))
        
        # í¬ë§¤í„°
        formatter = logging.Formatter(log_config['format'])
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        if log_config['file_handler']:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_file = log_dir / f"evaluation_{timestamp}.log"
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_handler.setFormatter(formatter)
            self.logger.addHandler(file_handler)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        if log_config['console_handler']:
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            self.logger.addHandler(console_handler)
    
    def setup_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
        directories = [
            self.config['data_paths']['output_dir'],
            self.config['data_paths']['logs_dir'],
            "evaluation/data",
            "evaluation/results/charts",
            "evaluation/results/reports"
        ]
        
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
        
        self.logger.info("ğŸ“ ë””ë ‰í† ë¦¬ ì„¤ì • ì™„ë£Œ")
    
    def check_server_health(self) -> bool:
        """ì„œë²„ ìƒíƒœ í™•ì¸"""
        self.logger.info("ğŸ” ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...")
        
        # RAG ì„œë²„ í™•ì¸
        try:
            rag_response = requests.get(
                f"{self.rag_server_url}/health",
                timeout=self.config['servers']['health_check_timeout']
            )
            if rag_response.status_code != 200:
                self.logger.error(f"âŒ RAG ì„œë²„ ìƒíƒœ ì´ìƒ: {rag_response.status_code}")
                return False
            self.logger.info("âœ… RAG ì„œë²„ ì •ìƒ")
        except Exception as e:
            self.logger.error(f"âŒ RAG ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
        
        # LLM ì„œë²„ í™•ì¸  
        try:
            llm_response = requests.get(
                f"{self.llm_server_url}/api/tags",
                timeout=self.config['servers']['health_check_timeout']
            )
            if llm_response.status_code != 200:
                self.logger.error(f"âŒ LLM ì„œë²„ ìƒíƒœ ì´ìƒ: {llm_response.status_code}")
                return False
            self.logger.info("âœ… LLM ì„œë²„ ì •ìƒ")
        except Exception as e:
            self.logger.error(f"âŒ LLM ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")
            return False
        
        return True
    
    def load_questions(self) -> pd.DataFrame:
        """í‰ê°€ìš© ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ"""
        questions_file = self.config['data_paths']['questions_file']
        
        try:
            if questions_file.endswith('.xlsx'):
                df = pd.read_excel(questions_file)
            elif questions_file.endswith('.csv'):
                df = pd.read_csv(questions_file)
            else:
                raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹")
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            required_columns = ['question', 'expected_answer', 'category']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
            
            # ìƒ˜í”Œë§ (ì„¤ì •ì— ë”°ë¼)
            sample_size = self.config['evaluation'].get('sample_size')
            if sample_size and sample_size < len(df):
                df = df.sample(n=sample_size, random_state=42)
                self.logger.info(f"ğŸ“Š {sample_size}ê°œ ì§ˆë¬¸ìœ¼ë¡œ ìƒ˜í”Œë§")
            
            self.logger.info(f"ğŸ“„ ì´ {len(df)}ê°œ ì§ˆë¬¸ ë¡œë“œ ì™„ë£Œ")
            return df
            
        except Exception as e:
            self.logger.error(f"âŒ ì§ˆë¬¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def get_rag_answer(self, question: str) -> Tuple[str, List[str]]:
        """RAG ì‹œìŠ¤í…œì—ì„œ ë‹µë³€ ë° ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # RAG ì±„íŒ… API í˜¸ì¶œ
            chat_payload = {
                "model": self.rag_model_name,
                "messages": [
                    {"role": "user", "content": question}
                ],
                "stream": False
            }
            
            response = requests.post(
                f"{self.rag_server_url}/api/chat",
                json=chat_payload,
                timeout=self.config['evaluation']['timeout_per_question']
            )
            
            if response.status_code != 200:
                raise Exception(f"API ì—ëŸ¬: {response.status_code}")
            
            result = response.json()
            answer = result.get('message', {}).get('content', '')
            
            # ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ë³„ë„ API)
            contexts = self.get_retrieved_contexts(question)
            
            return answer, contexts
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ RAG ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"Error: {str(e)}", []
    
    def get_rag_embeddings(self) -> Any:
        """RAG ì„œë²„ì˜ ì„ë² ë”© ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # RAG ì„œë²„ì˜ ì„ë² ë”© APIë¥¼ í†µí•´ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
            # ì´ê²ƒì€ ì‹¤ì œë¡œëŠ” RAG ì„œë²„ì˜ ì„ë² ë”© ëª¨ë¸ê³¼ ë™ì¼í•œ ëª¨ë¸ì„ ë¡œë“œ
            from embedding.bge_m3 import get_bge_m3_model
            return get_bge_m3_model()
        except Exception as e:
            self.logger.error(f"âŒ RAG ì„œë²„ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        """ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ë””ë²„ê·¸ API ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
            debug_payload = {"question": question}
            
            response = requests.post(
                f"{self.rag_server_url}/debug/test-retrieval",
                json=debug_payload,
                timeout=10
            )
            
            if response.status_code == 200:
                result = response.json()
                contexts = []
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œì—ì„œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
                retrieved_docs = result.get('retrieved_docs', [])
                for doc in retrieved_docs:
                    if isinstance(doc, dict):
                        content = doc.get('page_content', '')
                        if content:
                            contexts.append(content)
                    elif isinstance(doc, str):
                        contexts.append(doc)
                
                return contexts[:4]  # ìƒìœ„ 4ê°œë§Œ
            else:
                self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            self.logger.warning(f"ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
    
    def process_single_question(self, row: pd.Series) -> Dict[str, Any]:
        """ë‹¨ì¼ ì§ˆë¬¸ ì²˜ë¦¬"""
        question = row['question']
        expected_answer = row['expected_answer']
        category = row.get('category', 'Unknown')
        
        try:
            # RAG ì‹œìŠ¤í…œì—ì„œ ë‹µë³€ ë° ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
            answer, contexts = self.get_rag_answer(question)
            
            # ê²°ê³¼ êµ¬ì„±
            result = {
                'question': question,
                'answer': answer,
                'contexts': contexts,
                'ground_truth': expected_answer,
                'category': category,
                'timestamp': datetime.now().isoformat(),
                'success': True
            }
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì‹¤íŒ¨: {question[:50]}... | ì˜¤ë¥˜: {e}")
            return {
                'question': question,
                'answer': f"Error: {str(e)}",
                'contexts': [],
                'ground_truth': expected_answer,
                'category': category,
                'timestamp': datetime.now().isoformat(),
                'success': False,
                'error': str(e)
            }
    
    def process_questions_batch(self, questions_df: pd.DataFrame) -> List[Dict[str, Any]]:
        """ì§ˆë¬¸ ë°°ì¹˜ ì²˜ë¦¬"""
        self.logger.info(f"ğŸ”„ {len(questions_df)}ê°œ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì‘...")
        
        results = []
        batch_size = self.config['evaluation']['batch_size']
        max_workers = self.config['evaluation']['max_workers']
        
        # ë°°ì¹˜ë³„ ì²˜ë¦¬
        for i in range(0, len(questions_df), batch_size):
            batch = questions_df.iloc[i:i+batch_size]
            self.logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1}/{(len(questions_df)-1)//batch_size + 1} ì²˜ë¦¬ ì¤‘...")
            
            # ë³‘ë ¬ ì²˜ë¦¬
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                futures = []
                for _, row in batch.iterrows():
                    future = executor.submit(self.process_single_question, row)
                    futures.append(future)
                
                # ê²°ê³¼ ìˆ˜ì§‘ (ì§„í–‰ë¥  í‘œì‹œ)
                for future in tqdm(as_completed(futures), total=len(futures), desc="ì§ˆë¬¸ ì²˜ë¦¬"):
                    try:
                        result = future.result(timeout=self.config['evaluation']['timeout_per_question'])
                        results.append(result)
                    except Exception as e:
                        self.logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                        # ì—ëŸ¬ ê²°ê³¼ë„ ì¶”ê°€
                        results.append({
                            'question': 'Unknown',
                            'answer': f"Batch Error: {str(e)}",
                            'contexts': [],
                            'ground_truth': '',
                            'category': 'Error',
                            'success': False,
                            'error': str(e)
                        })
        
        self.logger.info(f"âœ… ì´ {len(results)}ê°œ ì§ˆë¬¸ ì²˜ë¦¬ ì™„ë£Œ")
        return results
    
    def prepare_ragas_dataset(self, results: List[Dict[str, Any]]) -> Dataset:
        """RAGAS í‰ê°€ìš© ë°ì´í„°ì…‹ ì¤€ë¹„"""
        self.logger.info("ğŸ“Š RAGAS ë°ì´í„°ì…‹ ì¤€ë¹„ ì¤‘...")
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        valid_results = [r for r in results if r.get('success', False)]
        self.logger.info(f"âœ… ìœ íš¨í•œ ê²°ê³¼: {len(valid_results)}/{len(results)}ê°œ")
        
        # RAGAS í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        dataset_dict = {
            'question': [],
            'answer': [],
            'contexts': [],
            'ground_truth': []
        }
        
        for result in valid_results:
            dataset_dict['question'].append(result['question'])
            dataset_dict['answer'].append(result['answer'])
            dataset_dict['contexts'].append(result['contexts'] or ['No context retrieved'])
            dataset_dict['ground_truth'].append(result['ground_truth'])
        
        dataset = Dataset.from_dict(dataset_dict)
        self.logger.info(f"ğŸ¯ RAGAS ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ: {len(dataset)}ê°œ í•­ëª©")
        
        return dataset